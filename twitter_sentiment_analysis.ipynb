{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tkGQV9qYjJ1w",
        "nvDEwqpdjRoj",
        "1FG_mkBCjV88",
        "A5HEmnJzjo7U",
        "RYQIhO3VSIZr",
        "tCfzDnmi-ctV",
        "FmHpud8m-kp9",
        "D4jn4sqRSRU7",
        "aRgglqXaWhFh",
        "ZQXEvzvUZGJn",
        "bu4BE6MAabej",
        "NZsv3XrMjx5J",
        "m7I6G75Rj219"
      ],
      "authorship_tag": "ABX9TyOYAWkXEtxM8Dtm7CujiCc+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JefteLG/Twitter_Sentiment_Analysis/blob/main/twitter_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8P3MLXMdRTQ"
      },
      "source": [
        "<center><h1><strong>Twitter Sentiment Analysis<strong><h1></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duqiar06fBqQ"
      },
      "source": [
        "O objetivo desse estudo de caso √© criar um modelo que analisa um ou mais Tweets para prever o sentimento(Positivo ou Negativo) presente em cada Tweet. √â usado o Processamento de linguagem natural(NLP) juntamente com aprendizagem de maquina para construir esse modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag4flFQjzhtb"
      },
      "source": [
        "luska = 'quero @user remover o @user agora'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lqDk7duzoWa"
      },
      "source": [
        "newtext = [word for word in luska.split()]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_BrfGxaK5T9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdw4YWIr4GNr"
      },
      "source": [
        "#Baixar os dados\n",
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/JefteLG/Twitter_Sentiment_Analysis/main/Data_Set/twitter.csv \\\n",
        "    -O /tmp/twitter.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRGF4vKf4W6s"
      },
      "source": [
        "tweets_df = pd.read_csv('/tmp/twitter.csv')\n",
        "tweets_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EL9iOzd42sZ"
      },
      "source": [
        "tweet = tweets_df[tweets_df['id']==4]['tweet'].iloc[0]\n",
        "tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVDDI6GJfsSy"
      },
      "source": [
        "!pip install demoji\n",
        "import demoji as em\n",
        "\n",
        "em.download_codes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWwlotCJg4se"
      },
      "source": [
        "text = 'Ol√° üòÄ'\n",
        "\n",
        "em.findall(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXNbx7fJj0kY",
        "outputId": "c4450eb7-2e19-4ad3-8e13-e4503629d920"
      },
      "source": [
        "from pprint import pprint\n",
        "seq = \"I bet you didn't know that üòÄ, üôã‚Äç‚ôÇÔ∏è, and üôã‚Äç‚ôÄÔ∏è are three different emojis.\"\n",
        "pprint(seq.encode('unicode-escape'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(b\"I bet you didn't know that \\\\xf0\\\\x9f\\\\x99\\\\x8b, \\\\U0001f64b\\\\u200d\\\\u2642\\\\\"\n",
            " b'ufe0f, and \\\\U0001f64b\\\\u200d\\\\u2640\\\\ufe0f are three different emojis.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2OXSA5xiPzo"
      },
      "source": [
        "# Estrutura do Projeto\n",
        "O projeto pr√°tico de An√°lise de sentimento do Twitter √© dividido nas seguintes tarefas:\n",
        "\n",
        "- Tarefa n¬∫ 1: Entender a Declara√ß√£o do Problema e o caso de neg√≥cios.\n",
        "- Tarefa n¬∫ 2: Importar bibliotecas e conjuntos de dados.\n",
        "- Tarefa n¬∫ 3: Executar a an√°lise explorat√≥ria de dados.\n",
        "- Tarefa n¬∫ 4: Plotar a nuvem de palavras.\n",
        "- Tarefa n¬∫ 5: Executar a limpeza de dados - remover pontua√ß√£o.\n",
        "- Tarefa n¬∫ 6: Executar a limpeza de dados - remover palavras de parada(stop words).\n",
        "- Tarefa n¬∫ 7: Executar vetoriza√ß√£o de contagem (Tokenization).\n",
        "- Tarefa n¬∫ 8: Criar um pipeline para remover palavras irrelevantes, pontua√ß√£o e realizar tokeniza√ß√£o.\n",
        "- Tarefa n¬∫ 9: Compreender a teoria e a intui√ß√£o por tr√°s dos classificadores Naive Bayes.\n",
        "- Tarefa n¬∫ 10: Treinar um Classificador Naive Bayes.\n",
        "- Tarefa n¬∫ 11: Avaliar o desempenho do modelo treinado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkGQV9qYjJ1w"
      },
      "source": [
        "## Tarefa n¬∫ 1: Entender a Declara√ß√£o do Problema e o caso de neg√≥cios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzAaeCtFkbGS"
      },
      "source": [
        "- Nesse notebook √© usado o Processamento de linguagem natural(NLP) juntamente com aprendizagem de maquina para construir um modelo que analisa milhares de Tweets para prever o sentimentos das pessoas.\n",
        "\n",
        "- A Inteligencia artificial e a analise de sentimentos baseadas em aprendizado de maquina √© crucial para empresas, visto que, os insight revelado pela analise visa indicar o grau de qualidade dos servi√ßos e/ou produtos da empresa de acordo com os clientes.(Trabalhos Futuros)\n",
        "\n",
        "- Esse projeto √© diretamente aplicav√©l a praticamente qualquer empresa que disponhe de meios onlines(Twitter, Instagran, Facebook, WebSite) para interagir com seus clientes.(Trabalhos Futuros)\n",
        "\n",
        "- Os algoritmos podem ser usados para detectar e possivelmente sinalizar autamaticamente tweets de odio e racismo.(Trabalhos Futuros)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvDEwqpdjRoj"
      },
      "source": [
        "## Tarefa n¬∫ 2: Importar bibliotecas e conjuntos de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iWAJGZ-nSc9"
      },
      "source": [
        "#Pacotes essenciais para analise numericas, manipula√ß√£o de data frames e visualiza√ß√£o de dados.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULlYu-EV-JHS",
        "outputId": "d8eead27-0a79-471b-e18b-256daeda82a9"
      },
      "source": [
        "# Pacote para a cria√ß√£o de nuuvens de palavras na tarefa n¬∫ 4\n",
        "!pip install WordCloud\n",
        "from wordcloud import WordCloud"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: WordCloud in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from WordCloud) (1.18.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from WordCloud) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQm_dk5noTY1"
      },
      "source": [
        "# A base de dados desse exemplo est√° no meu repositorio do github e pode ser baixada no link abaixo.\n",
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/JefteLG/Twitter_Sentiment_Analysis/main/Data_Set/twitter.csv \\\n",
        "    -O /tmp/twitter.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgzrtLjdsqFT"
      },
      "source": [
        "# Utilizando o pandas para ler o arquivo CSV e estrutura-lo em um data frame na variavel `tweets_df` por meio do metodo read_csv().\n",
        "tweets_df = pd.read_csv('/tmp/twitter.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmnIKKR_tDjr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "194c5a79-9248-41d5-917d-696d065cd542"
      },
      "source": [
        "# visualiza√ß√£o1.\n",
        "tweets_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goEV6Sck7LY_"
      },
      "source": [
        "# visualiza√ß√£o2.\n",
        "tweets_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dNaBl0Tu2v6"
      },
      "source": [
        "#Informa√ß√µes sobre a quantidade de Tweets, memoria, tipo de dados e dados faltantes.\n",
        "tweets_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1fkzOu8u3dQ"
      },
      "source": [
        "#Exclus√£o da coluna `id`, n√£o √© um dado relevante para o modelo.\n",
        "tweets_df = tweets_df.drop(columns=['id'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FG_mkBCjV88"
      },
      "source": [
        "## Tarefa n¬∫ 3: Executar a an√°lise explorat√≥ria de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIrEPJ-N_qdc"
      },
      "source": [
        "# Esta √© uma fun√ß√£o no n√≠vel dos eixos e desenhar√° o mapa de calor para os eixos ativos no momento. Nesse caso a fun√ß√£o verifica se existe dados faltantes.\n",
        "sns.heatmap(tweets_df.isnull(), yticklabels=False, cbar=False, cmap=\"Blues\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ydidIVtLsok"
      },
      "source": [
        "# O m√©todo sns.countplot() √© usado para mostrar as contagens de observa√ß√µes em cada categoria categ√≥rica usando barras(Histograma).\n",
        "sns.countplot(data=tweets_df, x='label', palette='Set2')\n",
        "plt.show()\n",
        "\n",
        "# sns.countplot(tweets_df['label'], label='Count', palette='Set2')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODWALt2K91Ma"
      },
      "source": [
        "# Nova coluna com o tamanho dos tweets\n",
        "tweets_df['length'] = tweets_df['tweet'].apply(len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "gPeDf5MXpY-U",
        "outputId": "35b73e5e-ec7d-4ee8-a3b9-22175f540be6"
      },
      "source": [
        "tweets_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?√∞¬ü¬ò¬ç√∞¬ü¬ò¬ç√∞¬ü¬ò¬ç√∞¬ü¬ò¬ç√∞¬ü¬ò¬ç√∞...</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label                                              tweet  length\n",
              "0          0   @user when a father is dysfunctional and is s...     102\n",
              "1          0  @user @user thanks for #lyft credit i can't us...     122\n",
              "2          0                                bihday your majesty      21\n",
              "3          0  #model   i love u take with u all the time in ...      86\n",
              "4          0             factsguide: society now    #motivation      39\n",
              "...      ...                                                ...     ...\n",
              "31957      0  ate @user isz that youuu?√∞¬ü¬ò¬ç√∞¬ü¬ò¬ç√∞¬ü¬ò¬ç√∞¬ü¬ò¬ç√∞¬ü¬ò¬ç√∞...      68\n",
              "31958      0    to see nina turner on the airwaves trying to...     131\n",
              "31959      0  listening to sad songs on a monday morning otw...      63\n",
              "31960      1  @user #sikh #temple vandalised in in #calgary,...      67\n",
              "31961      0                   thank you @user for you follow        32\n",
              "\n",
              "[31962 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI_41ZMN-TaI"
      },
      "source": [
        "# Descobrir o tamanho maximo, minimo e medio dos tweets.\n",
        "tweets_df['length'].plot(bins=100, kind='hist', figsize=(12,8), color='g')\n",
        "\n",
        "tweets_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_KTzfnzadgh"
      },
      "source": [
        "# Selecionar a menor frase\n",
        "tweets_df[tweets_df['length']==11]['tweet'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UqITftfiNIZ"
      },
      "source": [
        "# Separa o DataFrame em dois Dataframes, um com sentimentos positivos e o outro com sentimentos negativos.\n",
        "positive_df = tweets_df[tweets_df['label']==0]\n",
        "negative_df = tweets_df[tweets_df['label']==1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kppOxtAiu_Q"
      },
      "source": [
        "positive_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keY3soLSiweY"
      },
      "source": [
        "negative_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5HEmnJzjo7U"
      },
      "source": [
        "## Tarefa n¬∫ 4: Plotar a nuvem de palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz3DsDvrxwN1"
      },
      "source": [
        "# Criar uma lista de tweets\n",
        "sentences = tweets_df['tweet'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLDny0ox3CqD"
      },
      "source": [
        "# O m√©todo join() pega todos os itens em um iter√°vel e os une em uma string. √© usado o espa√ßo como separador\n",
        "sentences_as_one_string = \" \".join(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIm2zkE68BTi"
      },
      "source": [
        "# Nuvem de palavras de todos os tweets\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(WordCloud().generate(sentences_as_one_string))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBKJtXYnCiIV"
      },
      "source": [
        "# Nuvem de palavras de todos os tweets NEGATIVOS\n",
        "negative_sentences = negative_df['tweet'].tolist()\n",
        "negative_as_one_string = \" \".join(negative_sentences)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(WordCloud().generate(negative_as_one_string))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A54mv1tmD32T"
      },
      "source": [
        "# Nuvem de palavras de todos os tweets POSITIVOS\n",
        "positive_sentences = positive_df['tweet'].tolist()\n",
        "positive_as_one_string = \" \".join(positive_sentences)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(WordCloud().generate(positive_as_one_string))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-tiCTXdjsxh"
      },
      "source": [
        "## Tarefa n¬∫ 5: Executar a limpeza de dados - remover pontua√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cRytRI8O0HK"
      },
      "source": [
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uFn5yCbPOrL"
      },
      "source": [
        "text = 'Good morning beautiful people :)... I am having fun learning Machine learning and artificial intelligence'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxK8GFjgbJ0G"
      },
      "source": [
        "[Artigo sobre a remo√ß√£o de pontua√ß√µes de uma string](https://towardsdatascience.com/how-to-efficiently-remove-punctuations-from-a-string-899ad4a059fb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYQIhO3VSIZr"
      },
      "source": [
        "### Metodo #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCfzDnmi-ctV"
      },
      "source": [
        "#### Metodo #1.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVxmUCskQBxm"
      },
      "source": [
        "test_punc_remove = [char for char in text if char not in string.punctuation]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXSRQNuzQZ_2"
      },
      "source": [
        "test_punc_remove"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2Q5OH_AWqKp"
      },
      "source": [
        "test_punc_remove = ''.join(test_punc_remove)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdMeAyQZXF8S"
      },
      "source": [
        "test_punc_remove"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmHpud8m-kp9"
      },
      "source": [
        "#### Metodo #1.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnfRhlkG-oKb"
      },
      "source": [
        "text_remove_punct = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bElj4lx7-oDK"
      },
      "source": [
        "for char in text:\n",
        "  if char not in string.punctuation:\n",
        "    text_remove_punct.append(char)\n",
        "\n",
        "new_text = ''.join(text_remove_punct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMdjOxEC-n7E"
      },
      "source": [
        "new_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4jn4sqRSRU7"
      },
      "source": [
        "### Metodo #2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPGscUDASXic"
      },
      "source": [
        "punct = string.punctuation + string.digits  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3EBTeJkTTYT"
      },
      "source": [
        "table_tst = str.maketrans('','',punct)\n",
        "newtext = text.translate(table_tst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhv6s43CWH0D"
      },
      "source": [
        "newtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRgglqXaWhFh"
      },
      "source": [
        "### Metodo #3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6er7mq7ZBgi"
      },
      "source": [
        "punct = string.punctuation + string.digits  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMaSjYuEXO9_"
      },
      "source": [
        "table_ = str.maketrans(punct, ' '*len(punct))\n",
        "newtext = ' '.join(text.translate(table_).split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs3RJV2sZD43"
      },
      "source": [
        "newtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQXEvzvUZGJn"
      },
      "source": [
        "### Metodo #4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ1tH_mfZIsN"
      },
      "source": [
        "punct = string.punctuation + string.digits  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsMhHzNvZLcS"
      },
      "source": [
        "for s in punct:\n",
        "  text = text.replace(s, '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY7mlEIUZLUR"
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu4BE6MAabej"
      },
      "source": [
        "### Metodo #5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9ElzdhlaeIg"
      },
      "source": [
        "import re\n",
        "newtext = re.sub(r'[^A-Za-z]+', ' ', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9vhABfQadsI"
      },
      "source": [
        "newtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZsv3XrMjx5J"
      },
      "source": [
        "## Tarefa n¬∫ 6: Executar a limpeza de dados - remover palavras de parada(stop words)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw6Pxu__gPkh"
      },
      "source": [
        "#Pacotes para facilitar o processamento de linguagem natural\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG4VEtkrg1UA"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCxdrCa8QgWt"
      },
      "source": [
        "text = 'Good morning beautiful people :)... I am having fun learning Machine learning and artificial intelligence'\n",
        "\n",
        "# caracteres para remover\n",
        "puncts = string.digits + string.punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KO6IGRjRBYH"
      },
      "source": [
        "#remo√ß√£o de caracteres\n",
        "text_remove_punct = [char for char in text if char not in puncts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtxMfbn-TIkl"
      },
      "source": [
        "#pega todos os itens em um iter√°vel e os une em uma string.\n",
        "text_remove_punct = ''.join(text_remove_punct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU0hltVZT3Vg"
      },
      "source": [
        "text_remove_punct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra6faW2EQqqd"
      },
      "source": [
        "#remo√ß√£o de stopword\n",
        "text_remove_stopword = [word for word in text_remove_punct.split() if word.lower() not in stopwords.words('english')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2kFMXv6Uyex"
      },
      "source": [
        "text_remove_stopword"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7I6G75Rj219"
      },
      "source": [
        "## Tarefa n¬∫ 7: Executar vetoriza√ß√£o de contagem(Tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozUCJAzaY9hW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODahEnITj6hn"
      },
      "source": [
        "## Tarefa n¬∫ 8: Criar um pipeline para remover palavras irrelevantes, pontua√ß√£o e realizar tokeniza√ß√£o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB4wHNDdj-Rf"
      },
      "source": [
        "## Tarefa n¬∫ 9: Compreender a teoria e a intui√ß√£o por tr√°s dos classificadores Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOb9dWLEkCi6"
      },
      "source": [
        "## Tarefa n¬∫ 10: Treinar um Classificador Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ONuinVokIDF"
      },
      "source": [
        "## Tarefa n¬∫ 11: Avaliar o desempenho do modelo treinado"
      ]
    }
  ]
}